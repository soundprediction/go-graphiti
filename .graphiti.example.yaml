# Go-Graphiti Configuration Example
# Copy this file to .graphiti.yaml and customize for your setup
#
# This configuration shows options for external services.
# For minimal setup, use embedded ladybug database and local LLMs (no config required).

# Logging configuration
log:
  level: info      # debug, info, warn, error
  format: text     # text, json

# Server configuration
server:
  host: localhost
  port: 8080
  mode: debug      # debug, release, test

# Database configuration
database:
  driver: ladybug     # ladybug (embedded, recommended), neo4j, falkordb
  path: "./ladybug_db"  # For ladybug embedded database

  # Uncomment for external Neo4j database
  # driver: neo4j
  # uri: bolt://localhost:7687
  # username: neo4j
  # password: password
  # database: neo4j

# LLM configuration (supports any OpenAI-compatible API)
llm:
  provider: openai    # Works with OpenAI, Ollama, LocalAI, vLLM, etc.
  model: gpt-4o-mini  # For OpenAI, or "llama3.2" for Ollama, etc.
  api_key: ""         # Set via OPENAI_API_KEY environment variable (use "dummy" for Ollama)
  base_url: ""        # Optional: "http://localhost:11434" for Ollama, etc.
  temperature: 0.1
  max_tokens: 2048

  # Example configurations for local services:
  # For Ollama:
  # provider: openai
  # model: llama3.2
  # api_key: dummy
  # base_url: http://localhost:11434

# Embedding configuration (supports any OpenAI-compatible API)
embedding:
  provider: openai
  model: text-embedding-3-small  # Or local embedding model
  api_key: ""         # Set via OPENAI_API_KEY environment variable (use "dummy" for local)
  base_url: ""        # Optional: custom API endpoint for local services